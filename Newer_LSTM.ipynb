{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Christopher-Mao/AI-Practicum/blob/main/Newer_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "IS00u7rKnnRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants used below:\n",
        "# Set a custom sampling strategy (e.g., 0.25 means the minority class will be 25% of the majority class)\n",
        "sampling_ratio = 0.25  # Adjust this value as needed\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "seq_length = 5  # however long you want the training sequence to be\n",
        "\n",
        "hidden_size = 50  # Number of hidden units\n",
        "num_layers = 2  # Number of stacked LSTM layers"
      ],
      "metadata": {
        "id": "_meuoEuBI3uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.epa.gov/system/files/other-files/2023-08/ucmr5-occurrence-data.zip\n",
        "!unzip ucmr5-occurrence-data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLe166a3tplv",
        "outputId": "25e7f8fd-7f37-4dd1-d6cf-a79124a8758f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-08 02:02:52--  https://www.epa.gov/system/files/other-files/2023-08/ucmr5-occurrence-data.zip\n",
            "Resolving www.epa.gov (www.epa.gov)... 18.239.94.128, 18.239.94.26, 18.239.94.67, ...\n",
            "Connecting to www.epa.gov (www.epa.gov)|18.239.94.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8128843 (7.8M) [application/zip]\n",
            "Saving to: ‘ucmr5-occurrence-data.zip’\n",
            "\n",
            "ucmr5-occurrence-da 100%[===================>]   7.75M  9.16MB/s    in 0.8s    \n",
            "\n",
            "2024-12-08 02:02:53 (9.16 MB/s) - ‘ucmr5-occurrence-data.zip’ saved [8128843/8128843]\n",
            "\n",
            "Archive:  ucmr5-occurrence-data.zip\n",
            "  inflating: UCMR5_ZIPCodes.txt      \n",
            "  inflating: UCMR5_DataSummary_Oct2024_508.pdf  \n",
            "  inflating: InstructionsforAccessingUCMRResults_July2024_508.pdf  \n",
            "  inflating: UCMR5_AddtlDataElem.txt  \n",
            "  inflating: UCMR5_All.txt           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_pandas(file_path, sep='\\t', encoding='latin-1'):\n",
        "    df = pd.read_csv(file_path, sep=sep, encoding=encoding)\n",
        "    return df\n",
        "UCMR5_df = text_to_pandas('UCMR5_All.txt')"
      ],
      "metadata": {
        "id": "8K5GE7fwybwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "buPBHlyKSvot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(UCMR5_df.shape)\n",
        "# Drop unnecessary row 'lithium'\n",
        "UCMR5_filtered_df = UCMR5_df[~UCMR5_df['Contaminant'].str.contains('lithium', case=False, na=False)].copy()\n",
        "print(UCMR5_filtered_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4y4qQ0y7_2L",
        "outputId": "10f9a563-f069-4758-9133-e007b8090aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1133967, 24)\n",
            "(1095477, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UCMR5_filtered_df = UCMR5_filtered_df[['Size', 'FacilityWaterType', 'CollectionDate', 'Contaminant', 'AnalyticalResultsSign', 'Region']].copy()\n",
        "UCMR5_filtered_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8I3Rf4pwud2",
        "outputId": "a0506776-93b3-490e-bc29-2eef9c887fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1095477, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'CollectionDate' to datetime objects, handling potential errors\n",
        "UCMR5_filtered_df['CollectionDate'] = pd.to_datetime(UCMR5_filtered_df['CollectionDate'], errors='coerce')\n",
        "UCMR5_filtered_df['Year'] = UCMR5_filtered_df['CollectionDate'].dt.year\n",
        "UCMR5_filtered_df['Month'] = UCMR5_filtered_df['CollectionDate'].dt.month\n",
        "UCMR5_filtered_df['Day'] = UCMR5_filtered_df['CollectionDate'].dt.day\n",
        "UCMR5_filtered_df['Quarter'] = UCMR5_filtered_df['CollectionDate'].dt.quarter"
      ],
      "metadata": {
        "id": "bhlZRbFbSP9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Range of CollectionDate in UCMR5_filtered_df:\")\n",
        "print(UCMR5_filtered_df['CollectionDate'].min(), UCMR5_filtered_df['CollectionDate'].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD5u53BQWdnh",
        "outputId": "9e1dbbc3-6cbc-4451-b191-22985c0b25d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Range of CollectionDate in UCMR5_filtered_df:\n",
            "2023-01-03 00:00:00 2024-09-30 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model"
      ],
      "metadata": {
        "id": "M2xuxeg0S2E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check CUDA availability\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaAL-Sg_vGeL",
        "outputId": "be87b0c4-a630-449e-88c4-915f1be321f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Filter Data for Training and Prediction\n",
        "Training Data: Include only rows from 2023.\n",
        "Test Data (Prediction): Include only rows from 2024."
      ],
      "metadata": {
        "id": "88wM6fd3ynu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter training and prediction datasets\n",
        "train_data = UCMR5_filtered_df[UCMR5_filtered_df[\"Year\"] == 2023]\n",
        "test_data = UCMR5_filtered_df[UCMR5_filtered_df[\"Year\"] == 2024]\n",
        "\n",
        "# Separate features and target variable\n",
        "features = ['Size', 'FacilityWaterType', 'Month', 'Day', 'Contaminant', 'Region']\n",
        "target = 'AnalyticalResultsSign'\n",
        "\n",
        "X_train = train_data[features]\n",
        "y_train = train_data[target]\n",
        "\n",
        "X_test = test_data[features]"
      ],
      "metadata": {
        "id": "FuFKhCQeyesV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Preprocess the Data\n",
        "One-Hot Encoding and Normalization\n",
        "Ensure the test data (2024) uses the same encoding and normalization as the training data:"
      ],
      "metadata": {
        "id": "y6lb6JKNysDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode categorical features\n",
        "X_train = pd.get_dummies(X_train, columns=['Size', 'FacilityWaterType', 'Month', 'Day', 'Contaminant', 'Region'], drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, columns=['Size', 'FacilityWaterType', 'Month', 'Day', 'Contaminant', 'Region'], drop_first=True)\n",
        "# Ensure both datasets have the same columns\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "# Convert target to binary values\n",
        "y_train = (y_train == '=').astype(int)  # 1 for '=', 0 for '<'\n",
        "# Normalize or standardize features (optional)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "fyrqcm-BytFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Apply SMOTE or undersampling"
      ],
      "metadata": {
        "id": "pe4F3eM1_scP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE with the custom sampling ratio\n",
        "smote = SMOTE(sampling_strategy=sampling_ratio, random_state=42)  # Set random_state for reproducibility\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Print the class distribution before and after applying SMOTE\n",
        "print(\"Class distribution before SMOTE:\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "print(\"\\nClass distribution after SMOTE:\")\n",
        "print(pd.Series(y_train_resampled).value_counts())\n",
        "\n",
        "\n",
        "\n",
        "# # Undersampling\n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# # Apply undersampling to training data\n",
        "# undersampler = RandomUnderSampler(random_state=42)  # Set random_state for reproducibility\n",
        "# X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# # Print the class distribution before and after applying undersampling\n",
        "# print(\"Class distribution before undersampling:\")\n",
        "# print(pd.Series(y_train).value_counts())\n",
        "# print(\"\\nClass distribution after undersampling:\")\n",
        "# print(pd.Series(y_train_resampled).value_counts())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyyFG8OI_k0Y",
        "outputId": "c85d6cec-a15f-464e-be5d-e24d137701bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before SMOTE:\n",
            "AnalyticalResultsSign\n",
            "0    603961\n",
            "1     13120\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class distribution after SMOTE:\n",
            "AnalyticalResultsSign\n",
            "0    603961\n",
            "1    603961\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Convert Data to PyTorch Tensors"
      ],
      "metadata": {
        "id": "2lz-hOdByzvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define sequence length\n",
        "\n",
        "\n",
        "# Reshape X_train and y_train into sequences\n",
        "X_train_sequences = []\n",
        "y_train_sequences = []\n",
        "\n",
        "# Convert X_train and y_train into overlapping sequences\n",
        "for i in range(len(X_train) - seq_length + 1):\n",
        "    # Collect seq_length timesteps for input\n",
        "    X_train_sequences.append(X_train_resampled[i:i+seq_length, :])\n",
        "    # Use the value after the sequence as the target\n",
        "    y_train_sequences.append(y_train_resampled.values[i + seq_length - 1])\n",
        "\n",
        "# Convert sequences to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_sequences, dtype=torch.float32)  # Shape: (num_samples, seq_length, num_features)\n",
        "y_train_tensor = torch.tensor(y_train_sequences, dtype=torch.float32)  # Shape: (num_samples,)\n",
        "\n",
        "# Optionally repeat the process for X_test if necessary\n",
        "X_test_sequences = []\n",
        "for i in range(len(X_test) - seq_length + 1):\n",
        "    X_test_sequences.append(X_test[i:i+seq_length, :])\n",
        "X_test_tensor = torch.tensor(X_test_sequences, dtype=torch.float32)\n",
        "\n",
        "# Create DataLoader for training\n",
        "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "# Optional: Check shapes for debugging\n",
        "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")  # (num_samples, seq_length, num_features)\n",
        "print(f\"y_train_tensor shape: {y_train_tensor.shape}\")  # (num_samples,)\n"
      ],
      "metadata": {
        "id": "YmI81237y2Qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0564af4-b3d2-445f-ee13-9538b7ddb968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-9479462ccb4b>:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  X_train_tensor = torch.tensor(X_train_sequences, dtype=torch.float32)  # Shape: (num_samples, seq_length, num_features)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_tensor shape: torch.Size([617077, 5, 82])\n",
            "y_train_tensor shape: torch.Size([617077])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Define the LSTM Model ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)  # Output layer for regression\n",
        "\n",
        "        # Initialize hidden and cell states as None\n",
        "        self.hidden = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # If hidden states are None or the batch size changes, reinitialize them\n",
        "        if self.hidden is None or self.hidden[0].size(1) != x.size(0):\n",
        "            self.hidden = (\n",
        "                torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device),\n",
        "                torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device),\n",
        "            )\n",
        "\n",
        "        # Forward propagate through LSTM\n",
        "        out, self.hidden = self.lstm(x, self.hidden)\n",
        "\n",
        "        # Detach hidden states to prevent backprop through history\n",
        "        self.hidden = (self.hidden[0].detach(), self.hidden[1].detach())\n",
        "\n",
        "        # Fully connected layer on the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "\n",
        "    def reset_hidden_state(self):\n",
        "        \"\"\"Reset hidden and cell states (e.g., at the start of each epoch).\"\"\"\n",
        "        self.hidden = None\n"
      ],
      "metadata": {
        "id": "v2W2dMwfzlZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Initialize the Model, Loss Function, and Optimizer ---\n",
        "\n",
        "input_size = X_train_tensor.shape[2]  # Number of features. tensor is num_samples, seq_length, num_features\n",
        "\n",
        "model = LSTMModel(input_size, hidden_size, num_layers).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function for classification\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Optimizer"
      ],
      "metadata": {
        "id": "TafNpDxMzqt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# --- Step 5: Train the Model ---\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Reset hidden state at the start of each epoch (if needed)\n",
        "    if hasattr(model, \"reset_hidden_state\"):\n",
        "        model.reset_hidden_state()\n",
        "\n",
        "    # Use tqdm to create a progress bar\n",
        "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
        "        for X_batch, y_batch in pbar:\n",
        "            start_time = time.time()  # Start time for the batch\n",
        "\n",
        "            # Move data to device\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(X_batch).squeeze()\n",
        "            loss = criterion(predictions, y_batch)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update epoch loss\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # End time for the batch\n",
        "            batch_time = time.time() - start_time\n",
        "\n",
        "            # Update tqdm description\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.4f}\", batch_time=f\"{batch_time:.4f}s\")\n",
        "\n",
        "    # Print epoch-level results\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IrU_MmRzuMg",
        "outputId": "4ba03fc2-cded-4ac8-fdd3-a65db4f12260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 19284/19284 [04:04<00:00, 78.96batch/s, batch_time=0.0099s, loss=-0.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Loss: 1.55589321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 19284/19284 [03:48<00:00, 84.50batch/s, batch_time=0.0069s, loss=-0.0000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/2], Loss: 1.27639777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# --- Step 6: Make Predictions for 2024 ---\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    print(f\"Original X_test_tensor shape: {X_test_tensor.shape}\")  # Debug\n",
        "    X_test_tensor = X_test_tensor.to(device)  # Add time dimension and move to device\n",
        "    print(f\"Reshaped X_test_tensor shape: {X_test_tensor.shape}\")  # Debug\n",
        "\n",
        "    # Get model predictions\n",
        "    outputs = model(X_test_tensor)  # Raw logits or probabilities\n",
        "    predictions = torch.sigmoid(outputs).squeeze()  # Apply sigmoid for binary classification probabilities\n",
        "\n",
        "# Convert probabilities to binary class labels\n",
        "threshold = 0.5\n",
        "predicted_labels = (predictions > threshold).int()  # Convert probabilities to 0 or 1\n",
        "\n",
        "# Ensure alignment by dropping initial rows from test_data\n",
        "adjusted_test_data = test_data.iloc[seq_length - 1:].copy()\n",
        "\n",
        "# Add predictions to the adjusted DataFrame\n",
        "adjusted_test_data[\"PredictedSign\"] = predicted_labels.cpu().numpy()\n",
        "\n",
        "# Save the results\n",
        "adjusted_test_data.to_csv(\"predictions_2024.csv\", index=False)\n",
        "\n",
        "# Debugging: Check alignment\n",
        "print(f\"Adjusted test_data shape: {adjusted_test_data.shape}\")\n",
        "print(f\"PredictedSign shape: {predicted_labels.shape}\")\n",
        "\n",
        "# --- Optional: Evaluate the Model ---\n",
        "if 'AnalyticalResultsSign' in test_data.columns:\n",
        "    y_test = adjusted_test_data['AnalyticalResultsSign'].values\n",
        "    y_test_binary = (y_test == '=').astype(int)  # Convert ground truth to binary labels\n",
        "\n",
        "    # Convert ground truth to PyTorch tensor\n",
        "    y_test_tensor = torch.tensor(y_test_binary, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Ensure alignment\n",
        "    if len(predicted_labels) != len(y_test_tensor):\n",
        "        raise ValueError(\"Mismatch between predictions and ground truth values.\")\n",
        "\n",
        "    # Calculate accuracy\n",
        "    correct_predictions = (predicted_labels == y_test_tensor).sum().item()\n",
        "    accuracy = correct_predictions / len(y_test_tensor)\n",
        "\n",
        "    print(f\"Accuracy on 2024 data: {accuracy:.4f}\")\n",
        "\n",
        "    # Additional metrics (e.g., precision, recall, F1-score)\n",
        "    from sklearn.metrics import classification_report\n",
        "    print(classification_report(y_test_binary, predicted_labels.cpu().numpy()))\n",
        "\n",
        "    # --- Add Confusion Matrix ---\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    # Assuming y_test_binary and predicted_labels are defined as in your code\n",
        "    conf_matrix = confusion_matrix(y_test_binary, predicted_labels.cpu().numpy())\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6QVB0X67dzA",
        "outputId": "8a82849c-dd8e-4c09-a90a-049fbb2f7db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X_test_tensor shape: torch.Size([478392, 5, 82])\n",
            "Reshaped X_test_tensor shape: torch.Size([478392, 5, 82])\n",
            "Adjusted test_data shape: (478392, 11)\n",
            "PredictedSign shape: torch.Size([478392])\n",
            "Accuracy on 2024 data: 0.7450\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.74      0.85    469166\n",
            "           1       0.07      0.98      0.13      9226\n",
            "\n",
            "    accuracy                           0.74    478392\n",
            "   macro avg       0.53      0.86      0.49    478392\n",
            "weighted avg       0.98      0.74      0.84    478392\n",
            "\n",
            "Confusion Matrix:\n",
            "[[347365 121801]\n",
            " [   210   9016]]\n"
          ]
        }
      ]
    }
  ]
}